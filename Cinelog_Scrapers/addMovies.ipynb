{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Processing: Ala Vaikunthapurramuloo\n",
      "ðŸŽ¬ Processing: Arjun Reddy\n",
      "ðŸŽ¬ Processing: F2: Fun and Frustration\n",
      "ðŸŽ¬ Processing: Maharshi\n",
      "ðŸŽ¬ Processing: Bheeshma\n",
      "ðŸŽ¬ Processing: Saaho\n",
      "ðŸŽ¬ Processing: Kabir Singh\n",
      "ðŸŽ¬ Processing: Geetha Govindam\n",
      "ðŸŽ¬ Processing: Mahanati\n",
      "ðŸŽ¬ Processing: Rangasthalam\n",
      "ðŸŽ¬ Processing: Sye Raa Narasimha Reddy\n",
      "ðŸŽ¬ Processing: Nenu Sailaja\n",
      "ðŸŽ¬ Processing: Pelli Choopulu\n",
      "ðŸŽ¬ Processing: Dookudu\n",
      "ðŸŽ¬ Processing: Mirchi\n",
      "ðŸŽ¬ Processing: Businessman\n",
      "ðŸŽ¬ Processing: Autonagar Surya\n",
      "ðŸŽ¬ Processing: Premam\n",
      "ðŸŽ¬ Processing: Gentleman\n",
      "ðŸŽ¬ Processing: Kalyana Vaibhogame\n",
      "ðŸŽ¬ Processing: Srimanthudu\n",
      "ðŸŽ¬ Processing: Attarintiki Daredi\n",
      "ðŸŽ¬ Processing: Baahubali 2: The Conclusion\n",
      "ðŸŽ¬ Processing: Baahubali\n",
      "ðŸŽ¬ Processing: Ye Maaya Chesave\n",
      "ðŸŽ¬ Processing: Eega\n",
      "ðŸŽ¬ Processing: Dilwala\n",
      "ðŸŽ¬ Processing: Brahma\n",
      "ðŸŽ¬ Processing: Maheshinte Prathikaaram\n",
      "ðŸŽ¬ Processing: Aagadu\n",
      "ðŸŽ¬ Processing: Jai Lava Kusa\n",
      "ðŸŽ¬ Processing: Taxiwala\n",
      "ðŸŽ¬ Processing: RX100\n",
      "ðŸŽ¬ Processing: Kabali\n",
      "ðŸŽ¬ Processing: Janatha Garage\n",
      "ðŸŽ¬ Processing: Gaddalakonda Ganesh\n",
      "ðŸŽ¬ Processing: A..Aa\n",
      "ðŸŽ¬ Processing: Jawaan\n",
      "ðŸŽ¬ Processing: Naa Peru Surya\n",
      "ðŸŽ¬ Processing: Kalyana Vaibhogam\n",
      "ðŸŽ¬ Processing: LIE\n",
      "ðŸŽ¬ Processing: Sarrainodu\n",
      "ðŸŽ¬ Processing: Tippu\n",
      "ðŸŽ¬ Processing: D for Dopidi\n",
      "ðŸŽ¬ Processing: Gopala Gopala\n",
      "ðŸŽ¬ Processing: Courier Boy Kalyan\n",
      "ðŸŽ¬ Processing: Vedalam\n",
      "ðŸŽ¬ Processing: Anjali\n",
      "ðŸŽ¬ Processing: Pelli Sandadi\n",
      "ðŸŽ¬ Processing: Khaidi No.150\n",
      "ðŸŽ¬ Processing: Okkadu\n",
      "ðŸŽ¬ Processing: Gharshana\n",
      "ðŸŽ¬ Processing: Aadukalam\n",
      "ðŸŽ¬ Processing: Jabardasth\n",
      "ðŸŽ¬ Processing: Oxygen\n",
      "ðŸŽ¬ Processing: Thikka\n",
      "ðŸŽ¬ Processing: Kantri\n",
      "ðŸŽ¬ Processing: Aaha Kalyanam\n",
      "ðŸŽ¬ Processing: Khiladi Krishna\n",
      "ðŸŽ¬ Processing: Yatra\n",
      "ðŸŽ¬ Processing: Vunnadhi Okate Zindagi\n",
      "ðŸŽ¬ Processing: Raju Gadu\n",
      "ðŸŽ¬ Processing: Sneha Geetham\n",
      "ðŸŽ¬ Processing: Gaganam\n",
      "ðŸŽ¬ Processing: Arundhati\n",
      "ðŸŽ¬ Processing: Lakshmi Bomb\n",
      "ðŸŽ¬ Processing: Gajendra\n",
      "âœ… Data written to movies.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# === Load API keys ===\n",
    "load_dotenv()\n",
    "OMDB_KEY = os.getenv(\"OMDB_KEY\")  # Replace if needed\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# === Functions ===\n",
    "def fetch_omdb_data(title: str) -> dict:\n",
    "    url = f\"http://www.omdbapi.com/?t={title}&apikey={OMDB_KEY}\"\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "        if data.get(\"Response\") == \"True\":\n",
    "            return data\n",
    "    return {\"Error\": f\"No data found for {title}\"}\n",
    "\n",
    "def generate_tags(plot_and_genre: str) -> str:\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "Generate 3â€“5 lowercase tags (no hashtags or punctuation), separated by '|'.\n",
    "Do not explain or include extra text.\n",
    "\n",
    "Plot and Genre:\n",
    "{plot_and_genre}\n",
    "\n",
    "Tags:\n",
    "\"\"\")\n",
    "    _input = prompt.format(plot_and_genre=plot_and_genre)\n",
    "    result = llm.predict(_input).strip()\n",
    "    lines = result.splitlines()\n",
    "    tags = lines[-1].strip()\n",
    "    if \":\" in tags:\n",
    "        tags = tags.split(\":\")[-1].strip()\n",
    "    return tags.replace('\"', '').strip('.')\n",
    "\n",
    "# === Read movie titles ===\n",
    "with open(\"movies.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    movie_titles = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# === Output file (JSONL) ===\n",
    "output_file = \"movies.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for title in movie_titles:\n",
    "        print(f\"ðŸŽ¬ Processing: {title}\")\n",
    "        movie_data = fetch_omdb_data(title)\n",
    "        if \"Error\" in movie_data:\n",
    "            print(f\"âŒ Skipped {title}: {movie_data['Error']}\")\n",
    "            continue\n",
    "\n",
    "        plot = movie_data.get(\"Plot\", \"\")\n",
    "        genre = movie_data.get(\"Genre\", \"\").split(\",\")[0].strip()\n",
    "        tag_input = f\"{plot} Genre: {genre}\"\n",
    "        tags = generate_tags(tag_input)\n",
    "\n",
    "        json_record = {\n",
    "            \"title\": movie_data.get(\"Title\", \"\"),\n",
    "            \"plot\": plot,\n",
    "            \"director\": movie_data.get(\"Director\", \"\"),\n",
    "            \"genre\": genre,\n",
    "            \"rating\": movie_data.get(\"imdbRating\", \"\"),\n",
    "            \"release_date\": movie_data.get(\"Released\", \"\"),\n",
    "            \"language\": \"|\".join(lang.strip() for lang in movie_data.get(\"Language\", \"\").split(\",\")),\n",
    "            \"country\": \"|\".join(c.strip() for c in movie_data.get(\"Country\", \"\").split(\",\")),\n",
    "            \"cast\": \"|\".join(actor.strip() for actor in movie_data.get(\"Actors\", \"\").split(\",\")),\n",
    "            \"tags\": tags\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(json_record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Data written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce3567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Generating movie titles for: Top Tollywood (Telugu) movies, recent ones have higher priority\n",
      "ðŸ” Validating titles via OMDb...\n",
      "â© Skipping duplicate: Ala Vaikunthapurramuloo\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Rangasthalam\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Geetha Govindam\n",
      "â© Skipping duplicate: F2: Fun and Frustration\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Khaidi No.150\n",
      "â© Skipping duplicate: Okkadu\n",
      "â© Skipping duplicate: Gharshana\n",
      "â© Skipping duplicate: Aadukalam\n",
      "â© Skipping duplicate: Jabardasth\n",
      "â© Skipping duplicate: Oxygen\n",
      "â© Skipping duplicate: Thikka\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Kantri\n",
      "â© Skipping duplicate: Aaha Kalyanam\n",
      "â© Skipping duplicate: Khiladi Krishna\n",
      "â© Skipping duplicate: Yatra\n",
      "â© Skipping duplicate: Vunnadhi Okate Zindagi\n",
      "â© Skipping duplicate: Raju Gadu\n",
      "â© Skipping duplicate: Sneha Geetham\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Gaganam\n",
      "â© Skipping duplicate: Arundhati\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Lakshmi Bomb\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Gajendra\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Khaidi No.150\n",
      "â© Skipping duplicate: Okkadu\n",
      "â© Skipping duplicate: Gharshana\n",
      "â© Skipping duplicate: Aadukalam\n",
      "â© Skipping duplicate: Jabardasth\n",
      "â© Skipping duplicate: Oxygen\n",
      "â© Skipping duplicate: Thikka\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Kantri\n",
      "â© Skipping duplicate: Aaha Kalyanam\n",
      "â© Skipping duplicate: Khiladi Krishna\n",
      "â© Skipping duplicate: Yatra\n",
      "â© Skipping duplicate: Vunnadhi Okate Zindagi\n",
      "â© Skipping duplicate: Raju Gadu\n",
      "â© Skipping duplicate: Sneha Geetham\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Gaganam\n",
      "â© Skipping duplicate: Arundhati\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Lakshmi Bomb\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Gajendra\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Khaidi No.150\n",
      "â© Skipping duplicate: Okkadu\n",
      "â© Skipping duplicate: Gharshana\n",
      "â© Skipping duplicate: Aadukalam\n",
      "â© Skipping duplicate: Jabardasth\n",
      "â© Skipping duplicate: Oxygen\n",
      "â© Skipping duplicate: Thikka\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Kantri\n",
      "â© Skipping duplicate: Aaha Kalyanam\n",
      "â© Skipping duplicate: Khiladi Krishna\n",
      "â© Skipping duplicate: Yatra\n",
      "â© Skipping duplicate: Vunnadhi Okate Zindagi\n",
      "â© Skipping duplicate: Raju Gadu\n",
      "â© Skipping duplicate: Sneha Geetham\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Gaganam\n",
      "â© Skipping duplicate: Arundhati\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Lakshmi Bomb\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Gajendra\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Khaidi No.150\n",
      "â© Skipping duplicate: Okkadu\n",
      "â© Skipping duplicate: Gharshana\n",
      "â© Skipping duplicate: Aadukalam\n",
      "â© Skipping duplicate: Jabardasth\n",
      "â© Skipping duplicate: Oxygen\n",
      "â© Skipping duplicate: Thikka\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Kantri\n",
      "â© Skipping duplicate: Aaha Kalyanam\n",
      "â© Skipping duplicate: Khiladi Krishna\n",
      "â© Skipping duplicate: Yatra\n",
      "â© Skipping duplicate: Vunnadhi Okate Zindagi\n",
      "â© Skipping duplicate: Raju Gadu\n",
      "â© Skipping duplicate: Sneha Geetham\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Gaganam\n",
      "â© Skipping duplicate: Arundhati\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Lakshmi Bomb\n",
      "â© Skipping duplicate: Mahanati\n",
      "â© Skipping duplicate: Gajendra\n",
      "â© Skipping duplicate: Arjun Reddy\n",
      "â© Skipping duplicate: Maharshi\n",
      "â© Skipping duplicate: Srimanthudu\n",
      "â© Skipping duplicate: Khaidi No.150\n",
      "â© Skipping duplicate: Okkadu\n",
      "â© Skipping duplicate: Gharshana\n",
      "â© Skipping duplicate: Aadukalam\n",
      "â© Skipping duplicate: Jabardasth\n",
      "â© Skipping duplicate: Oxygen\n",
      "â© Skipping duplicate: Thikka\n",
      "â© Skipping duplicate: Gentleman\n",
      "â© Skipping duplicate: Kantri\n",
      "â© Skipping duplicate: Aaha Kalyanam\n",
      "â© Skipping duplicate: Khiladi Krishna\n",
      "â© Skipping duplicate: Yatra\n",
      "â© Skipping duplicate: Vunnadhi Okate Zindagi\n",
      "â© Skipping duplicate: Raju Gadu\n",
      "â© Skipping duplicate: Sneha Geetham\n",
      "â© Skipping duplicate: Maheshinte Prathikaaram\n",
      "â© Skipping duplicate: Sarrainodu\n",
      "â© Skipping duplicate: Gaganam\n",
      "â© Skipping duplicate: Arundhati\n",
      "â© Skipping duplicate: Eega\n",
      "â© Skipping duplicate: Aagadu\n",
      "â© Skipping duplicate: Nenu Sailaja\n",
      "â© Skipping duplicate: Lakshmi Bomb\n",
      "âœ… 34 new movie titles appended to movies.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OMDB_KEY = os.getenv(\"OMDB_KEY\")  # or os.getenv(\"OMDB_KEY\")\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# === Function to fetch basic OMDb validation ===\n",
    "def omdb_title_exists(title: str) -> bool:\n",
    "    url = f\"http://www.omdbapi.com/?t={title}&apikey={OMDB_KEY}\"\n",
    "    res = requests.get(url)\n",
    "    data = res.json()\n",
    "    return data.get(\"Response\") == \"True\"\n",
    "\n",
    "# === Agent to generate titles ===\n",
    "def generate_movie_titles(user_prompt: str, count: int) -> list:\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "Generate a list of {count} real movie titles based on this request:\n",
    "\n",
    "\"{user_prompt}\"\n",
    "\n",
    "Only list the movie titles, each on a new line. Do not include extra descriptions or numbering.\n",
    "\"\"\")\n",
    "    formatted_prompt = prompt.format(user_prompt=user_prompt, count=count)\n",
    "    raw_output = llm.predict(formatted_prompt)\n",
    "\n",
    "    # Clean and split titles\n",
    "    titles = [line.strip().strip('\"') for line in raw_output.splitlines() if line.strip()]\n",
    "    return titles\n",
    "\n",
    "# === Main method ===\n",
    "def populate_movies_txt(user_prompt: str, count: int, output_file=\"movies.txt\"):\n",
    "    print(f\"ðŸŽ¬ Generating movie titles for: {user_prompt}\")\n",
    "    titles = generate_movie_titles(user_prompt, count)\n",
    "\n",
    "    # Load existing titles\n",
    "    existing_titles = set()\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing_titles = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "    print(f\"ðŸ” Validating titles via OMDb...\")\n",
    "    valid_titles = []\n",
    "    for title in titles:\n",
    "        if title in existing_titles:\n",
    "            print(f\"â© Skipping duplicate: {title}\")\n",
    "            continue\n",
    "        if omdb_title_exists(title):\n",
    "            valid_titles.append(title)\n",
    "            existing_titles.add(title)  # Add to avoid future duplication\n",
    "        if len(valid_titles) >= count:\n",
    "            break\n",
    "\n",
    "    if not valid_titles:\n",
    "        print(\"âš ï¸ No new valid titles found.\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        for title in valid_titles:\n",
    "            f.write(title + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… {len(valid_titles)} new movie titles appended to {output_file}\")\n",
    "\n",
    "# === Example usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Top Hollywood movies, recent ones have higher priority, but maintain some old classical movies as well\"\n",
    "    populate_movies_txt(prompt, count=5000)  # Start with 100 during testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58a33817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 0 movies to movies.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_imdb_list_titles(url, max_count=500):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    titles = []\n",
    "\n",
    "    for item in soup.select(\".lister-item-header a\"):\n",
    "        if len(titles) >= max_count:\n",
    "            break\n",
    "        titles.append(item.text.strip())\n",
    "\n",
    "    return titles\n",
    "\n",
    "def save_to_movies_txt(titles, filename=\"movies.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for title in titles:\n",
    "            f.write(title + \"\\n\")\n",
    "    print(f\"âœ… Saved {len(titles)} movies to {filename}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.imdb.com/india/top-rated-telugu-movies/\"  # Replace with your chosen IMDb list\n",
    "titles = fetch_imdb_list_titles(url)\n",
    "save_to_movies_txt(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74761666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 0.2/1.0 MB 7.3 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.4/1.0 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 0.7/1.0 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "     ---------------------------------------- 0.0/755.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 256.0/755.0 kB 7.9 MB/s eta 0:00:01\n",
      "     ----------------------- -------------- 471.0/755.0 kB 7.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  747.5/755.0 kB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 755.0/755.0 kB 6.0 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/2.1 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.6/2.1 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.9/2.1 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.1 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.5/2.1 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.8/2.1 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 7.5 MB/s eta 0:00:00\n",
      "Collecting pydantic<3.0.0,>=2.7.4\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "     ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "     -------------------------------------  440.3/444.8 kB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 444.8/444.8 kB 6.9 MB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "     ---------------------------------------- 0.0/161.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 161.8/161.8 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "     ---------------------------------------- 0.0/438.9 kB ? eta -:--:--\n",
      "     -------------------------------- ---- 389.1/438.9 kB 23.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 438.9/438.9 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting langsmith>=0.1.17\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "     ---------------------------------------- 0.0/367.7 kB ? eta -:--:--\n",
      "     ---------------------------------- -- 337.9/367.7 kB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 367.7/367.7 kB 7.6 MB/s eta 0:00:00\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 73.5/73.5 kB ? eta 0:00:00\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "     ---------------------------------------- 0.0/207.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 207.5/207.5 kB 6.4 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 100.9/100.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\vb\\onedrive\\documents\\vscode_workspace\\cinelog_scrapers\\clip-ai-env\\lib\\site-packages (from openai) (4.14.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "     ---------------------------------------- 0.0/157.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 157.7/157.7 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "     ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 129.8/129.8 kB 7.5 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vb\\onedrive\\documents\\vscode_workspace\\cinelog_scrapers\\clip-ai-env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.8/78.8 kB ? eta 0:00:00\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting packaging<25,>=23.2\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl (134 kB)\n",
      "     ---------------------------------------- 0.0/134.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 134.6/134.6 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "     ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 54.5/54.5 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "     ---------------------------------------- 0.0/495.5 kB ? eta -:--:--\n",
      "     ----------------------------------- - 481.3/495.5 kB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- 495.5/495.5 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.4/2.0 MB 13.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.9/2.0 MB 11.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.3/2.0 MB 10.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.7/2.0 MB 11.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting greenlet>=1\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl (296 kB)\n",
      "     ---------------------------------------- 0.0/296.6 kB ? eta -:--:--\n",
      "     ------------------------------------ - 286.7/296.6 kB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 296.6/296.6 kB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\vb\\onedrive\\documents\\vscode_workspace\\cinelog_scrapers\\clip-ai-env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tqdm, tenacity, sniffio, PyYAML, python-dotenv, pydantic-core, packaging, orjson, jsonpointer, jiter, idna, h11, greenlet, distro, charset_normalizer, certifi, async-timeout, annotated-types, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.41 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 certifi-2025.6.15 charset_normalizer-3.4.2 distro-1.9.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.26 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.4 openai-1.93.0 orjson-3.10.18 packaging-24.2 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tqdm-4.67.1 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e71ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: open_clip_torch in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (2.32.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: regex in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (2024.11.6)\n",
      "Requirement already satisfied: ftfy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (6.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (0.33.4)\n",
      "Requirement already satisfied: safetensors in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (0.5.3)\n",
      "Requirement already satisfied: timm in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from open_clip_torch) (1.0.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from huggingface-hub->open_clip_torch) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from tqdm->open_clip_torch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: ftfy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from ftfy) (0.2.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\vamsi\\appdata\\local\\temp\\pip-req-build-homwvpb4\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from clip==1.0) (0.22.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torch->clip==1.0) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision->clip==1.0) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from torchvision->clip==1.0) (11.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\vamsi\\AppData\\Local\\Temp\\pip-req-build-homwvpb4'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Getting requirements to build wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"c:\\Users\\vamsi\\Documents\\Cinelog_Movie_Tracker\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\vamsi\\Documents\\Cinelog_Movie_Tracker\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\vamsi\\Documents\\Cinelog_Movie_Tracker\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Temp\\pip-build-env-72fxx5cb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Temp\\pip-build-env-72fxx5cb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Temp\\pip-build-env-72fxx5cb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Temp\\pip-build-env-72fxx5cb\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m414\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1039\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\vamsi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1551\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] The system cannot find the file specified\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Ã— Getting requirements to build wheel did not run successfully.\n",
      "â”‚ exit code: 1\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vamsi\\documents\\cinelog_movie_tracker\\venv\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.8 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.7/10.8 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.8 MB 24.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 23.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 15.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.21.2 transformers-4.53.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4 torch torchvision open_clip_torch\n",
    "%pip install torch torchvision ftfy regex tqdm\n",
    "%pip install git+https://github.com/openai/CLIP.git\n",
    "%pip install python-dotenv\n",
    "%pip install sentencepiece --prefer-binary\n",
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83457ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vamsi\\Documents\\Cinelog_Movie_Tracker\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Processing: Ala Vaikunthapurramuloo\n",
      "ðŸŽ¬ Processing: Arjun Reddy\n",
      "ðŸŽ¬ Processing: F2: Fun and Frustration\n",
      "ðŸŽ¬ Processing: Maharshi\n",
      "ðŸŽ¬ Processing: Bheeshma\n",
      "ðŸŽ¬ Processing: Saaho\n",
      "ðŸŽ¬ Processing: Kabir Singh\n",
      "ðŸŽ¬ Processing: Geetha Govindam\n",
      "ðŸŽ¬ Processing: Mahanati\n",
      "ðŸŽ¬ Processing: Rangasthalam\n",
      "ðŸŽ¬ Processing: Sye Raa Narasimha Reddy\n",
      "ðŸŽ¬ Processing: Nenu Sailaja\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002770121A890>\n",
      "âš ï¸ Skipped Nenu Sailaja: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Pelli Choopulu\n",
      "ðŸŽ¬ Processing: Dookudu\n",
      "ðŸŽ¬ Processing: Mirchi\n",
      "ðŸŽ¬ Processing: Businessman\n",
      "ðŸŽ¬ Processing: Autonagar Surya\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054B1F0>\n",
      "âš ï¸ Skipped Autonagar Surya: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Premam\n",
      "ðŸŽ¬ Processing: Gentleman\n",
      "ðŸŽ¬ Processing: Kalyana Vaibhogame\n",
      "ðŸŽ¬ Processing: Srimanthudu\n",
      "ðŸŽ¬ Processing: Attarintiki Daredi\n",
      "ðŸŽ¬ Processing: Baahubali 2: The Conclusion\n",
      "ðŸŽ¬ Processing: Baahubali\n",
      "ðŸŽ¬ Processing: Ye Maaya Chesave\n",
      "ðŸŽ¬ Processing: Eega\n",
      "ðŸŽ¬ Processing: Dilwala\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002770121A890>\n",
      "âš ï¸ Skipped Dilwala: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Brahma\n",
      "ðŸŽ¬ Processing: Maheshinte Prathikaaram\n",
      "ðŸŽ¬ Processing: Aagadu\n",
      "ðŸŽ¬ Processing: Jai Lava Kusa\n",
      "ðŸŽ¬ Processing: Taxiwala\n",
      "ðŸŽ¬ Processing: RX100\n",
      "âŒ Skipped RX100: No valid poster URL\n",
      "ðŸŽ¬ Processing: Kabali\n",
      "ðŸŽ¬ Processing: Janatha Garage\n",
      "ðŸŽ¬ Processing: Gaddalakonda Ganesh\n",
      "ðŸŽ¬ Processing: A..Aa\n",
      "ðŸŽ¬ Processing: Jawaan\n",
      "ðŸŽ¬ Processing: Naa Peru Surya\n",
      "ðŸŽ¬ Processing: Kalyana Vaibhogam\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054BF60>\n",
      "âš ï¸ Skipped Kalyana Vaibhogam: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: LIE\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x0000027701210A90>\n",
      "âš ï¸ Skipped LIE: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Sarrainodu\n",
      "ðŸŽ¬ Processing: Tippu\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x0000027701210A90>\n",
      "âš ï¸ Skipped Tippu: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: D for Dopidi\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054B1F0>\n",
      "âš ï¸ Skipped D for Dopidi: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Gopala Gopala\n",
      "ðŸŽ¬ Processing: Courier Boy Kalyan\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x0000027701270860>\n",
      "âš ï¸ Skipped Courier Boy Kalyan: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Vedalam\n",
      "ðŸŽ¬ Processing: Anjali\n",
      "ðŸŽ¬ Processing: Pelli Sandadi\n",
      "ðŸŽ¬ Processing: Khaidi No.150\n",
      "ðŸŽ¬ Processing: Okkadu\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x00000277012101D0>\n",
      "âš ï¸ Skipped Okkadu: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Gharshana\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002770121A890>\n",
      "âš ï¸ Skipped Gharshana: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Aadukalam\n",
      "ðŸŽ¬ Processing: Jabardasth\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002770121A890>\n",
      "âš ï¸ Skipped Jabardasth: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Oxygen\n",
      "ðŸŽ¬ Processing: Thikka\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054BE70>\n",
      "âš ï¸ Skipped Thikka: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Kantri\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x0000027701210A90>\n",
      "âš ï¸ Skipped Kantri: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Aaha Kalyanam\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054BE70>\n",
      "âš ï¸ Skipped Aaha Kalyanam: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Khiladi Krishna\n",
      "âŒ Skipped Khiladi Krishna: No valid poster URL\n",
      "ðŸŽ¬ Processing: Yatra\n",
      "ðŸŽ¬ Processing: Vunnadhi Okate Zindagi\n",
      "ðŸŽ¬ Processing: Raju Gadu\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002777054BE70>\n",
      "âš ï¸ Skipped Raju Gadu: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Sneha Geetham\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x00000277012701D0>\n",
      "âš ï¸ Skipped Sneha Geetham: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Gaganam\n",
      "ðŸŽ¬ Processing: Arundhati\n",
      "ðŸŽ¬ Processing: Lakshmi Bomb\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x0000027701270450>\n",
      "âš ï¸ Skipped Lakshmi Bomb: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Gajendra\n",
      "ðŸŽ¬ Processing: Avengers: Endgame\n",
      "ðŸŽ¬ Processing: Toy Story 4\n",
      "ðŸŽ¬ Processing: The Lion King\n",
      "ðŸŽ¬ Processing: Jumanji: The Next Level\n",
      "ðŸŽ¬ Processing: Spider-Man: Far From Home\n",
      "ðŸŽ¬ Processing: Captain Marvel\n",
      "ðŸŽ¬ Processing: Aladdin\n",
      "ðŸŽ¬ Processing: Star Wars: The Rise of Skywalker\n",
      "ðŸŽ¬ Processing: Frozen II\n",
      "ðŸŽ¬ Processing: A Quiet Place Part II\n",
      "ðŸŽ¬ Processing: Once Upon a Time in Hollywood\n",
      "âŒ Skipped Once Upon a Time in Hollywood: No valid poster URL\n",
      "ðŸŽ¬ Processing: 1917\n",
      "ðŸŽ¬ Processing: Knives Out\n",
      "ðŸŽ¬ Processing: Ford v Ferrari\n",
      "ðŸŽ¬ Processing: Joker\n",
      "ðŸŽ¬ Processing: Us\n",
      "ðŸŽ¬ Processing: Toy Story 3\n",
      "ðŸŽ¬ Processing: The Avengers\n",
      "ðŸŽ¬ Processing: Inception\n",
      "ðŸŽ¬ Processing: The Dark Knight Rises\n",
      "ðŸŽ¬ Processing: Titanic\n",
      "ðŸŽ¬ Processing: The Social Network\n",
      "ðŸŽ¬ Processing: The Silence of the Lambs\n",
      "ðŸŽ¬ Processing: Forrest Gump\n",
      "ðŸŽ¬ Processing: Pulp Fiction\n",
      "ðŸŽ¬ Processing: The Shawshank Redemption\n",
      "ðŸŽ¬ Processing: The Godfather\n",
      "ðŸŽ¬ Processing: Goodfellas\n",
      "ðŸŽ¬ Processing: Taxi Driver\n",
      "ðŸŽ¬ Processing: Rear Window\n",
      "ðŸŽ¬ Processing: Vertigo\n",
      "ðŸŽ¬ Processing: North by Northwest\n",
      "ðŸŽ¬ Processing: Casablanca\n",
      "ðŸŽ¬ Processing: It's a Wonderful Life\n",
      "ðŸŽ¬ Processing: Citizen Kane\n",
      "ðŸŽ¬ Processing: 2001: A Space Odyssey\n",
      "ðŸŽ¬ Processing: The Sound of Music\n",
      "ðŸŽ¬ Processing: E.T. the Extra-Terrestrial\n",
      "ðŸŽ¬ Processing: Jaws\n",
      "ðŸŽ¬ Processing: Raiders of the Lost Ark\n",
      "ðŸŽ¬ Processing: Indiana Jones and the Last Crusade\n",
      "ðŸŽ¬ Processing: Jurassic Park\n",
      "ðŸŽ¬ Processing: The Sixth Sense\n",
      "ðŸŽ¬ Processing: The Matrix\n",
      "ðŸŽ¬ Processing: American Beauty\n",
      "ðŸŽ¬ Processing: The Lord of the Rings: The Return of the King\n",
      "ðŸŽ¬ Processing: The Lord of the Rings: The Fellowship of the Ring\n",
      "ðŸŽ¬ Processing: The Lord of the Rings: The Two Towers\n",
      "ðŸŽ¬ Processing: The Princess Bride\n",
      "ðŸŽ¬ Processing: Ghostbusters\n",
      "ðŸŽ¬ Processing: Back to the Future\n",
      "ðŸŽ¬ Processing: The Terminator\n",
      "ðŸŽ¬ Processing: E.T.\n",
      "ðŸŽ¬ Processing: Star Wars: Episode IV - A New Hope\n",
      "ðŸŽ¬ Processing: The Godfather: Part II\n",
      "ðŸŽ¬ Processing: Apocalypse Now\n",
      "ðŸŽ¬ Processing: The Untouchables\n",
      "ðŸŽ¬ Processing: The Good, the Bad and the Ugly\n",
      "ðŸŽ¬ Processing: Butch Cassidy and the Sundance Kid\n",
      "ðŸŽ¬ Processing: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\n",
      "ðŸŽ¬ Processing: 200 Cigarettes\n",
      "ðŸŽ¬ Processing: 3:10 to Yuma\n",
      "ðŸŽ¬ Processing: 42nd Street\n",
      "ðŸŽ¬ Processing: Ace Ventura: Pet Detective\n",
      "ðŸŽ¬ Processing: Amadeus\n",
      "ðŸŽ¬ Processing: Annie Hall\n",
      "ðŸŽ¬ Processing: Apocalypto\n",
      "ðŸŽ¬ Processing: Armageddon\n",
      "ðŸŽ¬ Processing: Army of Darkness\n",
      "ðŸŽ¬ Processing: Austin Powers in Goldmember\n",
      "ðŸŽ¬ Processing: Avatar\n",
      "ðŸŽ¬ Processing: The Babadook\n",
      "ðŸŽ¬ Processing: Bad Boys II\n",
      "ðŸŽ¬ Processing: Backdraft\n",
      "ðŸŽ¬ Processing: Barton Fink\n",
      "ðŸŽ¬ Processing: Batman Begins\n",
      "ðŸŽ¬ Processing: Batman Forever\n",
      "ðŸŽ¬ Processing: Battle Royale\n",
      "ðŸŽ¬ Processing: Beetlejuice\n",
      "ðŸŽ¬ Processing: The Big Lebowski\n",
      "ðŸŽ¬ Processing: Big Trouble in Little China\n",
      "ðŸŽ¬ Processing: Blade Runner\n",
      "ðŸŽ¬ Processing: Blues Brothers\n",
      "ðŸŽ¬ Processing: Bowfinger\n",
      "ðŸŽ¬ Processing: Braveheart\n",
      "ðŸŽ¬ Processing: Brighton Rock\n",
      "ðŸŽ¬ Processing: Captain America: The First Avenger\n",
      "ðŸŽ¬ Processing: Casino Royale\n",
      "ðŸŽ¬ Processing: Clerks\n",
      "ðŸŽ¬ Processing: Closer\n",
      "ðŸŽ¬ Processing: Close Encounters of the Third Kind\n",
      "ðŸŽ¬ Processing: Coming to America\n",
      "ðŸŽ¬ Processing: Con Air\n",
      "ðŸŽ¬ Processing: The Counterfeiters\n",
      "ðŸŽ¬ Processing: Creed II\n",
      "ðŸŽ¬ Processing: Dances with Wolves\n",
      "ðŸŽ¬ Processing: Dark City\n",
      "ðŸŽ¬ Processing: Dead Man Walking\n",
      "ðŸŽ¬ Processing: Die Hard\n",
      "ðŸŽ¬ Processing: Dirty Dancing\n",
      "ðŸŽ¬ Processing: Do the Right Thing\n",
      "ðŸŽ¬ Processing: Donnie Darko\n",
      "ðŸŽ¬ Processing: Driving Miss Daisy\n",
      "ðŸŽ¬ Processing: Eagle vs Shark\n",
      "ðŸŽ¬ Processing: Easy Rider\n",
      "ðŸŽ¬ Processing: Edward Scissorhands\n",
      "ðŸŽ¬ Processing: Elf\n",
      "ðŸŽ¬ Processing: The English Patient\n",
      "ðŸŽ¬ Processing: Erin Brockovich\n",
      "ðŸŽ¬ Processing: Eternal Sunshine of the Spotless Mind\n",
      "ðŸŽ¬ Processing: Evil Dead II\n",
      "ðŸŽ¬ Processing: Fargo\n",
      "ðŸŽ¬ Processing: Fear and Loathing in Las Vegas\n",
      "ðŸŽ¬ Processing: Fight Club\n",
      "ðŸŽ¬ Processing: Finding Nemo\n",
      "ðŸŽ¬ Processing: Four Weddings and a Funeral\n",
      "ðŸŽ¬ Processing: Freeway\n",
      "ðŸŽ¬ Processing: Friday Night Lights\n",
      "ðŸŽ¬ Processing: Ghostbusters II\n",
      "ðŸŽ¬ Processing: Glory\n",
      "ðŸŽ¬ Processing: The Godfather Part III\n",
      "ðŸŽ¬ Processing: Gravity\n",
      "ðŸŽ¬ Processing: Gremlins\n",
      "ðŸŽ¬ Processing: Groundhog Day\n",
      "ðŸŽ¬ Processing: Guerrilla\n",
      "âš ï¸ Image embedding failed: cannot identify image file <_io.BytesIO object at 0x000002770121B1F0>\n",
      "âš ï¸ Skipped Guerrilla: Image embedding failed or poster unavailable\n",
      "ðŸŽ¬ Processing: Hannibal\n",
      "ðŸŽ¬ Processing: The Hangover\n",
      "ðŸŽ¬ Processing: Harry Potter and the Deathly Hallows â€“ Part 2\n",
      "ðŸŽ¬ Processing: Harry Potter and the Philosopher's Stone\n",
      "ðŸŽ¬ Processing: Harry Potter and the Prisoner of Azkaban\n",
      "ðŸŽ¬ Processing: Hercules\n",
      "ðŸŽ¬ Processing: Hidden Figures\n",
      "ðŸŽ¬ Processing: High Noon\n",
      "ðŸŽ¬ Processing: Home Alone\n",
      "ðŸŽ¬ Processing: Hotel Transylvania\n",
      "ðŸŽ¬ Processing: How to Train Your Dragon\n",
      "ðŸŽ¬ Processing: I Am Legend\n",
      "ðŸŽ¬ Processing: Ice Age: Dawn of the Dinosaurs\n",
      "ðŸŽ¬ Processing: In the Mood for Love\n",
      "ðŸŽ¬ Processing: Independence Day\n",
      "ðŸŽ¬ Processing: Indiana Jones and the Kingdom of the Crystal Skull\n",
      "ðŸŽ¬ Processing: The Incredibles\n",
      "ðŸŽ¬ Processing: Iron Man\n",
      "ðŸŽ¬ Processing: It Happened One Night\n",
      "ðŸŽ¬ Processing: Jagged Edge\n",
      "ðŸŽ¬ Processing: Johnny Guitar\n",
      "ðŸŽ¬ Processing: Jurassic World\n",
      "ðŸŽ¬ Processing: Karate Kid Part II\n",
      "ðŸŽ¬ Processing: Keanu Reeves\n",
      "ðŸŽ¬ Processing: Kill Bill: Vol. 1\n",
      "ðŸŽ¬ Processing: King Kong\n",
      "ðŸŽ¬ Processing: Knights of the Round Table\n",
      "ðŸŽ¬ Processing: Lady Bird\n",
      "ðŸŽ¬ Processing: Lagaan\n",
      "ðŸŽ¬ Processing: La La Land\n",
      "ðŸŽ¬ Processing: The Last King of Scotland\n",
      "ðŸŽ¬ Processing: The Last Samurai\n",
      "ðŸŽ¬ Processing: Let the Right One In\n",
      "ðŸŽ¬ Processing: Little Miss Sunshine\n",
      "âŒ Skipped Little Miss Sunshine: No data found for Little Miss Sunshine\n",
      "ðŸŽ¬ Processing: Lord of War\n",
      "âŒ Skipped Lord of War: No data found for Lord of War\n",
      "ðŸŽ¬ Processing: Lost in Translation\n",
      "ðŸŽ¬ Processing: Madagascar 3: Europe's Most Wanted\n",
      "ðŸŽ¬ Processing: Magnolia\n",
      "âŒ Skipped Magnolia: No data found for Magnolia\n",
      "ðŸŽ¬ Processing: Man on Wire\n",
      "âŒ Skipped Man on Wire: No data found for Man on Wire\n",
      "ðŸŽ¬ Processing: Maniac Cop\n",
      "âŒ Skipped Maniac Cop: No data found for Maniac Cop\n",
      "ðŸŽ¬ Processing: Mars Attacks!\n",
      "âŒ Skipped Mars Attacks!: No data found for Mars Attacks!\n",
      "ðŸŽ¬ Processing: Mary Poppins Returns\n",
      "âŒ Skipped Mary Poppins Returns: No data found for Mary Poppins Returns\n",
      "ðŸŽ¬ Processing: The Matrix Revolutions\n",
      "âŒ Skipped The Matrix Revolutions: No data found for The Matrix Revolutions\n",
      "ðŸŽ¬ Processing: Mean Streets\n",
      "âŒ Skipped Mean Streets: No data found for Mean Streets\n",
      "ðŸŽ¬ Processing: Meet Me in St. Louis\n",
      "âŒ Skipped Meet Me in St. Louis: No data found for Meet Me in St. Louis\n",
      "ðŸŽ¬ Processing: Melancholia\n",
      "âŒ Skipped Melancholia: No data found for Melancholia\n",
      "ðŸŽ¬ Processing: Menace II Society\n",
      "âŒ Skipped Menace II Society: No data found for Menace II Society\n",
      "ðŸŽ¬ Processing: Men of Honor\n",
      "âŒ Skipped Men of Honor: No data found for Men of Honor\n",
      "ðŸŽ¬ Processing: Mermaids\n",
      "âŒ Skipped Mermaids: No data found for Mermaids\n",
      "ðŸŽ¬ Processing: The Mighty Ducks\n",
      "âŒ Skipped The Mighty Ducks: No data found for The Mighty Ducks\n",
      "ðŸŽ¬ Processing: Million Dollar Baby\n",
      "âŒ Skipped Million Dollar Baby: No data found for Million Dollar Baby\n",
      "ðŸŽ¬ Processing: Moonrise Kingdom\n",
      "âŒ Skipped Moonrise Kingdom: No data found for Moonrise Kingdom\n",
      "ðŸŽ¬ Processing: Mrs. Doubtfire\n",
      "âŒ Skipped Mrs. Doubtfire: No data found for Mrs. Doubtfire\n",
      "ðŸŽ¬ Processing: Murder by Numbers\n",
      "âŒ Skipped Murder by Numbers: No data found for Murder by Numbers\n",
      "ðŸŽ¬ Processing: Music and Lyrics\n",
      "âŒ Skipped Music and Lyrics: No data found for Music and Lyrics\n",
      "ðŸŽ¬ Processing: My Big Fat Greek Wedding\n",
      "âŒ Skipped My Big Fat Greek Wedding: No data found for My Big Fat Greek Wedding\n",
      "ðŸŽ¬ Processing: My Fair Lady\n",
      "âŒ Skipped My Fair Lady: No data found for My Fair Lady\n",
      "ðŸŽ¬ Processing: My Girl\n",
      "âŒ Skipped My Girl: No data found for My Girl\n",
      "ðŸŽ¬ Processing: Mystic River\n",
      "âŒ Skipped Mystic River: No data found for Mystic River\n",
      "ðŸŽ¬ Processing: Napoleon Dynamite\n",
      "âŒ Skipped Napoleon Dynamite: No data found for Napoleon Dynamite\n",
      "ðŸŽ¬ Processing: Natural Born Killers\n",
      "âŒ Skipped Natural Born Killers: No data found for Natural Born Killers\n",
      "ðŸŽ¬ Processing: Night at the Museum: Secret of the Tomb\n",
      "âŒ Skipped Night at the Museum: Secret of the Tomb: No data found for Night at the Museum: Secret of the Tomb\n",
      "ðŸŽ¬ Processing: No Country for Old Men\n",
      "âŒ Skipped No Country for Old Men: No data found for No Country for Old Men\n",
      "ðŸŽ¬ Processing: Notting Hill\n",
      "âŒ Skipped Notting Hill: No data found for Notting Hill\n",
      "ðŸŽ¬ Processing: Ocean's Eleven\n",
      "âŒ Skipped Ocean's Eleven: No data found for Ocean's Eleven\n",
      "ðŸŽ¬ Processing: Once in a Lifetime\n",
      "âŒ Skipped Once in a Lifetime: No data found for Once in a Lifetime\n",
      "ðŸŽ¬ Processing: One Flew Over the Cuckoo's Nest\n",
      "âŒ Skipped One Flew Over the Cuckoo's Nest: No data found for One Flew Over the Cuckoo's Nest\n",
      "ðŸŽ¬ Processing: Open Range\n",
      "âŒ Skipped Open Range: No data found for Open Range\n",
      "ðŸŽ¬ Processing: The Other Boleyn Girl\n",
      "âŒ Skipped The Other Boleyn Girl: No data found for The Other Boleyn Girl\n",
      "ðŸŽ¬ Processing: Pacino\n",
      "âŒ Skipped Pacino: No data found for Pacino\n",
      "ðŸŽ¬ Processing: Paprika\n",
      "âŒ Skipped Paprika: No data found for Paprika\n",
      "ðŸŽ¬ Processing: Paranormal Activity 2\n",
      "ðŸŽ¬ Processing: Paris, Texas\n",
      "ðŸŽ¬ Processing: Patriot Games\n",
      "ðŸŽ¬ Processing: Pearl Harbor\n",
      "âŒ Skipped Pearl Harbor: No data found for Pearl Harbor\n",
      "ðŸŽ¬ Processing: The People vs. Larry Flynt\n",
      "âŒ Skipped The People vs. Larry Flynt: No data found for The People vs. Larry Flynt\n",
      "ðŸŽ¬ Processing: Philadelphia\n",
      "ðŸŽ¬ Processing: Planet of the Apes\n",
      "âŒ Skipped Planet of the Apes: No data found for Planet of the Apes\n",
      "ðŸŽ¬ Processing: Play It Again, Sam\n",
      "âŒ Skipped Play It Again, Sam: No data found for Play It Again, Sam\n",
      "ðŸŽ¬ Processing: Police Story\n",
      "âŒ Skipped Police Story: No data found for Police Story\n",
      "ðŸŽ¬ Processing: The Princess Diaries\n",
      "âŒ Skipped The Princess Diaries: No data found for The Princess Diaries\n",
      "ðŸŽ¬ Processing: The Pursuit of Happyness\n",
      "ðŸŽ¬ Processing: Rambo: First Blood Part II\n",
      "âŒ Skipped Rambo: First Blood Part II: No data found for Rambo: First Blood Part II\n",
      "ðŸŽ¬ Processing: Ray\n",
      "ðŸŽ¬ Processing: Rebel Without a Cause\n",
      "âŒ Skipped Rebel Without a Cause: No data found for Rebel Without a Cause\n",
      "ðŸŽ¬ Processing: Red Dragon\n",
      "âŒ Skipped Red Dragon: No data found for Red Dragon\n",
      "ðŸŽ¬ Processing: Repo Man\n",
      "âŒ Skipped Repo Man: No data found for Repo Man\n",
      "ðŸŽ¬ Processing: Reservoir Dogs\n",
      "âŒ Skipped Reservoir Dogs: No data found for Reservoir Dogs\n",
      "ðŸŽ¬ Processing: The Ring\n",
      "âŒ Skipped The Ring: No data found for The Ring\n",
      "ðŸŽ¬ Processing: River's Edge\n",
      "âŒ Skipped River's Edge: No data found for River's Edge\n",
      "ðŸŽ¬ Processing: Road House\n",
      "âŒ Skipped Road House: No data found for Road House\n",
      "ðŸŽ¬ Processing: Robots\n",
      "âŒ Skipped Robots: No data found for Robots\n",
      "ðŸŽ¬ Processing: Rocky IV\n",
      "âŒ Skipped Rocky IV: No data found for Rocky IV\n",
      "ðŸŽ¬ Processing: Roman Holiday\n",
      "âŒ Skipped Roman Holiday: No data found for Roman Holiday\n",
      "ðŸŽ¬ Processing: Ronin\n",
      "âŒ Skipped Ronin: No data found for Ronin\n",
      "ðŸŽ¬ Processing: Rosemary's Baby\n",
      "âŒ Skipped Rosemary's Baby: No data found for Rosemary's Baby\n",
      "ðŸŽ¬ Processing: Scent of a Woman\n",
      "âŒ Skipped Scent of a Woman: No data found for Scent of a Woman\n",
      "ðŸŽ¬ Processing: Schindler's List\n",
      "âŒ Skipped Schindler's List: No data found for Schindler's List\n",
      "ðŸŽ¬ Processing: Scott Pilgrim vs. the World\n",
      "âŒ Skipped Scott Pilgrim vs. the World: No data found for Scott Pilgrim vs. the World\n",
      "ðŸŽ¬ Processing: Se7en\n",
      "âŒ Skipped Se7en: No data found for Se7en\n",
      "ðŸŽ¬ Processing: Secrets & Lies\n",
      "âŒ Skipped Secrets & Lies: No data found for Secrets & Lies\n",
      "ðŸŽ¬ Processing: Seven Pounds\n",
      "âŒ Skipped Seven Pounds: No data found for Seven Pounds\n",
      "ðŸŽ¬ Processing: Shallow Grave\n",
      "âŒ Skipped Shallow Grave: No data found for Shallow Grave\n",
      "ðŸŽ¬ Processing: She's All That\n",
      "âŒ Skipped She's All That: No data found for She's All That\n",
      "ðŸŽ¬ Processing: Sherlock Holmes: A Game of Shadows\n",
      "âŒ Skipped Sherlock Holmes: A Game of Shadows: No data found for Sherlock Holmes: A Game of Shadows\n",
      "ðŸŽ¬ Processing: Shutter Island\n",
      "âŒ Skipped Shutter Island: No data found for Shutter Island\n",
      "ðŸŽ¬ Processing: Sideways\n",
      "âŒ Skipped Sideways: No data found for Sideways\n",
      "ðŸŽ¬ Processing: Signs\n",
      "âŒ Skipped Signs: No data found for Signs\n",
      "ðŸŽ¬ Processing: Skyfall\n",
      "âŒ Skipped Skyfall: No data found for Skyfall\n",
      "ðŸŽ¬ Processing: Slumdog Millionaire\n",
      "âŒ Skipped Slumdog Millionaire: No data found for Slumdog Millionaire\n",
      "ðŸŽ¬ Processing: Some Like It Hot\n",
      "âŒ Skipped Some Like It Hot: No data found for Some Like It Hot\n",
      "ðŸŽ¬ Processing: Sophie's Choice\n",
      "âŒ Skipped Sophie's Choice: No data found for Sophie's Choice\n",
      "ðŸŽ¬ Processing: Speed\n",
      "âŒ Skipped Speed: No data found for Speed\n",
      "ðŸŽ¬ Processing: Spider-Man 3\n",
      "âŒ Skipped Spider-Man 3: No data found for Spider-Man 3\n",
      "ðŸŽ¬ Processing: Star Wars: Episode VI - Return of the Jedi\n",
      "âŒ Skipped Star Wars: Episode VI - Return of the Jedi: No data found for Star Wars: Episode VI - Return of the Jedi\n",
      "ðŸŽ¬ Processing: Star Wars: Episode VII - The Force Awakens\n",
      "âŒ Skipped Star Wars: Episode VII - The Force Awakens: No data found for Star Wars: Episode VII - The Force Awakens\n",
      "ðŸŽ¬ Processing: Star Wars: Episode VIII - The Last Jedi\n",
      "âŒ Skipped Star Wars: Episode VIII - The Last Jedi: No data found for Star Wars: Episode VIII - The Last Jedi\n",
      "ðŸŽ¬ Processing: The Station Agent\n",
      "âŒ Skipped The Station Agent: No data found for The Station Agent\n",
      "ðŸŽ¬ Processing: Stepmom\n",
      "âŒ Skipped Stepmom: No data found for Stepmom\n",
      "ðŸŽ¬ Processing: Strange Days\n",
      "âŒ Skipped Strange Days: No data found for Strange Days\n",
      "ðŸŽ¬ Processing: Stranger Than Fiction\n",
      "âŒ Skipped Stranger Than Fiction: No data found for Stranger Than Fiction\n",
      "ðŸŽ¬ Processing: The Straight Story\n",
      "âŒ Skipped The Straight Story: No data found for The Straight Story\n",
      "ðŸŽ¬ Processing: Straw Dogs\n",
      "âŒ Skipped Straw Dogs: No data found for Straw Dogs\n",
      "ðŸŽ¬ Processing: Submarine\n",
      "âŒ Skipped Submarine: No data found for Submarine\n",
      "ðŸŽ¬ Processing: Super Size Me\n",
      "âŒ Skipped Super Size Me: No data found for Super Size Me\n",
      "ðŸŽ¬ Processing: That Thing You Do!\n",
      "âŒ Skipped That Thing You Do!: No data found for That Thing You Do!\n",
      "ðŸŽ¬ Processing: The Thin Red Line\n",
      "âŒ Skipped The Thin Red Line: No data found for The Thin Red Line\n",
      "ðŸŽ¬ Processing: This Is Spinal Tap\n",
      "ðŸŽ¬ Processing: Thor\n",
      "âŒ Skipped Thor: No data found for Thor\n",
      "ðŸŽ¬ Processing: Three Billboards Outside Ebbing, Missouri\n",
      "âŒ Skipped Three Billboards Outside Ebbing, Missouri: No data found for Three Billboards Outside Ebbing, Missouri\n",
      "ðŸŽ¬ Processing: Time After Time\n",
      "âŒ Skipped Time After Time: No data found for Time After Time\n",
      "ðŸŽ¬ Processing: Tin Cup\n",
      "âŒ Skipped Tin Cup: No data found for Tin Cup\n",
      "ðŸŽ¬ Processing: To Catch a Thief\n",
      "âŒ Skipped To Catch a Thief: No data found for To Catch a Thief\n",
      "ðŸŽ¬ Processing: Top Gun\n",
      "âŒ Skipped Top Gun: No data found for Top Gun\n",
      "ðŸŽ¬ Processing: Toy Story\n",
      "âŒ Skipped Toy Story: No data found for Toy Story\n",
      "ðŸŽ¬ Processing: Traffic\n",
      "âŒ Skipped Traffic: No data found for Traffic\n",
      "ðŸŽ¬ Processing: The Truman Show\n",
      "ðŸŽ¬ Processing: The Twilight Saga: Breaking Dawn - Part 2\n",
      "âŒ Skipped The Twilight Saga: Breaking Dawn - Part 2: No data found for The Twilight Saga: Breaking Dawn - Part 2\n",
      "ðŸŽ¬ Processing: Twister\n",
      "âŒ Skipped Twister: No data found for Twister\n",
      "ðŸŽ¬ Processing: Unbreakable Kimmy Schmidt\n",
      "âŒ Skipped Unbreakable Kimmy Schmidt: No data found for Unbreakable Kimmy Schmidt\n",
      "ðŸŽ¬ Processing: United 93\n",
      "âŒ Skipped United 93: No data found for United 93\n",
      "ðŸŽ¬ Processing: Up\n",
      "âŒ Skipped Up: No data found for Up\n",
      "ðŸŽ¬ Processing: Usual Suspects\n",
      "âŒ Skipped Usual Suspects: No data found for Usual Suspects\n",
      "ðŸŽ¬ Processing: V for Vendetta\n",
      "âŒ Skipped V for Vendetta: No data found for V for Vendetta\n",
      "ðŸŽ¬ Processing: Valentine's Day\n",
      "âŒ Skipped Valentine's Day: No data found for Valentine's Day\n",
      "ðŸŽ¬ Processing: Van Helsing\n",
      "âŒ Skipped Van Helsing: No data found for Van Helsing\n",
      "ðŸŽ¬ Processing: Victoria & Abdul\n",
      "âŒ Skipped Victoria & Abdul: No data found for Victoria & Abdul\n",
      "ðŸŽ¬ Processing: A View to a Kill\n",
      "âŒ Skipped A View to a Kill: No data found for A View to a Kill\n",
      "ðŸŽ¬ Processing: Walk the Line\n",
      "ðŸŽ¬ Processing: WALL-E\n",
      "âŒ Skipped WALL-E: No data found for WALL-E\n",
      "ðŸŽ¬ Processing: War of the Worlds\n",
      "âŒ Skipped War of the Worlds: No data found for War of the Worlds\n",
      "ðŸŽ¬ Processing: Waterworld\n",
      "âŒ Skipped Waterworld: No data found for Waterworld\n",
      "ðŸŽ¬ Processing: The Way Way Back\n",
      "ðŸŽ¬ Processing: Wedding Crashers\n",
      "âŒ Skipped Wedding Crashers: No data found for Wedding Crashers\n",
      "ðŸŽ¬ Processing: What's Eating Gilbert Grape\n",
      "âŒ Skipped What's Eating Gilbert Grape: No data found for What's Eating Gilbert Grape\n",
      "ðŸŽ¬ Processing: When Harry Met Sally\n",
      "âŒ Skipped When Harry Met Sally: No data found for When Harry Met Sally\n",
      "ðŸŽ¬ Processing: While You Were Sleeping\n",
      "âŒ Skipped While You Were Sleeping: No data found for While You Were Sleeping\n",
      "ðŸŽ¬ Processing: Who Framed Roger Rabbit\n",
      "âŒ Skipped Who Framed Roger Rabbit: No data found for Who Framed Roger Rabbit\n",
      "ðŸŽ¬ Processing: Witness\n",
      "ðŸŽ¬ Processing: X-Men: The Last Stand\n",
      "âŒ Skipped X-Men: The Last Stand: No data found for X-Men: The Last Stand\n",
      "ðŸŽ¬ Processing: X2: X-Men United\n",
      "âŒ Skipped X2: X-Men United: No data found for X2: X-Men United\n",
      "ðŸŽ¬ Processing: X-Men: First Class\n",
      "âŒ Skipped X-Men: First Class: No data found for X-Men: First Class\n",
      "ðŸŽ¬ Processing: You've Got Mail\n",
      "âŒ Skipped You've Got Mail: No data found for You've Got Mail\n",
      "ðŸŽ¬ Processing: Kadal\n",
      "âŒ Skipped Kadal: No data found for Kadal\n",
      "ðŸŽ¬ Processing: Thalaivaa\n",
      "âŒ Skipped Thalaivaa: No data found for Thalaivaa\n",
      "ðŸŽ¬ Processing: Thirudan Police\n",
      "âŒ Skipped Thirudan Police: No data found for Thirudan Police\n",
      "ðŸŽ¬ Processing: Rajini Murugan\n",
      "ðŸŽ¬ Processing: Nanban\n",
      "âŒ Skipped Nanban: No data found for Nanban\n",
      "ðŸŽ¬ Processing: Vivegam\n",
      "âŒ Skipped Vivegam: No data found for Vivegam\n",
      "ðŸŽ¬ Processing: Naayika\n",
      "âŒ Skipped Naayika: No data found for Naayika\n",
      "ðŸŽ¬ Processing: Velaikkaran\n",
      "âŒ Skipped Velaikkaran: No data found for Velaikkaran\n",
      "ðŸŽ¬ Processing: Tik Tik Tik\n",
      "âŒ Skipped Tik Tik Tik: No data found for Tik Tik Tik\n",
      "ðŸŽ¬ Processing: Iruvar\n",
      "âŒ Skipped Iruvar: No data found for Iruvar\n",
      "ðŸŽ¬ Processing: Udhayam NH4\n",
      "âŒ Skipped Udhayam NH4: No data found for Udhayam NH4\n",
      "ðŸŽ¬ Processing: Vikram Vedha\n",
      "âŒ Skipped Vikram Vedha: No data found for Vikram Vedha\n",
      "ðŸŽ¬ Processing: Irandam Ulagam\n",
      "âŒ Skipped Irandam Ulagam: No data found for Irandam Ulagam\n",
      "ðŸŽ¬ Processing: Idhayam\n",
      "âŒ Skipped Idhayam: No data found for Idhayam\n",
      "ðŸŽ¬ Processing: Raja Rani\n",
      "âŒ Skipped Raja Rani: No data found for Raja Rani\n",
      "ðŸŽ¬ Processing: Ponniyin Selvan\n",
      "âŒ Skipped Ponniyin Selvan: No data found for Ponniyin Selvan\n",
      "ðŸŽ¬ Processing: Anbe Sivam\n",
      "âŒ Skipped Anbe Sivam: No data found for Anbe Sivam\n",
      "ðŸŽ¬ Processing: Pithamagan\n",
      "âŒ Skipped Pithamagan: No data found for Pithamagan\n",
      "âœ… Data written to movies.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline\n",
    "\n",
    "# === Load API Key ===\n",
    "load_dotenv()\n",
    "OMDB_KEY = os.getenv(\"OMDB_KEY\")\n",
    "\n",
    "# === Load Models ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "tagger = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "# === Functions ===\n",
    "def fetch_omdb_data(title: str) -> dict:\n",
    "    url = f\"http://www.omdbapi.com/?t={title}&apikey={OMDB_KEY}\"\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "        if data.get(\"Response\") == \"True\":\n",
    "            return data\n",
    "    return {\"Error\": f\"No data found for {title}\"}\n",
    "\n",
    "def get_image_embedding(image_url: str):\n",
    "    try:\n",
    "        img = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n",
    "        img_preprocessed = clip_preprocess(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(img_preprocessed)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        return image_features[0].cpu().tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Image embedding failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_text_embedding(text: str):\n",
    "    try:\n",
    "        tokens = clip.tokenize([text]).to(device)\n",
    "        with torch.no_grad():\n",
    "            text_features = clip_model.encode_text(tokens)\n",
    "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        return text_features[0].cpu().tolist()\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Text embedding failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_tags(prompt_text: str) -> str:\n",
    "    try:\n",
    "        prompt = (\n",
    "            \"You're a helpful assistant. Read the following movie plot and genre. \"\n",
    "            \"Generate exactly 3 to 5 tags that are each a single word or short phrase. \"\n",
    "            \"Do not write full sentences, explanations, or include punctuation. \"\n",
    "            \"Return tags only, all in lowercase, separated by '|'.\\n\\n\"\n",
    "            f\"{prompt_text}\\n\\nTags:\"\n",
    "        )\n",
    "\n",
    "        result = tagger(prompt, max_length=64)[0]['generated_text']\n",
    "\n",
    "        # Extract tags portion after \"Tags:\"\n",
    "        tags_text = result.split(\"Tags:\")[-1].strip()\n",
    "\n",
    "        # Post-process to ensure tag formatting\n",
    "        tags = tags_text.lower().strip().strip('.')\n",
    "        tags = tags.replace(\",\", \"|\").replace(\";\", \"|\")\n",
    "        tags_list = [tag.strip() for tag in tags.split(\"|\") if tag.strip()]\n",
    "\n",
    "        # Keep only 3â€“5 tags\n",
    "        return \"|\".join(tags_list[:5])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Tag generation failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "# === Read movie titles ===\n",
    "with open(\"movies.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    movie_titles = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# === Output file ===\n",
    "output_file = \"movies.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for title in movie_titles:\n",
    "        print(f\"ðŸŽ¬ Processing: {title}\")\n",
    "        movie_data = fetch_omdb_data(title)\n",
    "        if \"Error\" in movie_data:\n",
    "            print(f\"âŒ Skipped {title}: {movie_data['Error']}\")\n",
    "            continue\n",
    "\n",
    "        poster_url = movie_data.get(\"Poster\", \"\")\n",
    "        if not poster_url or poster_url == \"N/A\":\n",
    "            print(f\"âŒ Skipped {title}: No valid poster URL\")\n",
    "            continue\n",
    "\n",
    "        plot = movie_data.get(\"Plot\", \"\")\n",
    "        genre = movie_data.get(\"Genre\", \"\").split(\",\")[0].strip()\n",
    "\n",
    "        text_input = f\"{plot} Genre: {genre}\"\n",
    "        text_embedding = get_text_embedding(text_input)\n",
    "        image_embedding = get_image_embedding(poster_url)\n",
    "        if not image_embedding:\n",
    "            print(f\"âš ï¸ Skipped {title}: Image embedding failed or poster unavailable\")\n",
    "            continue\n",
    "\n",
    "        #tags = generate_tags(text_input)\n",
    "        #print(tags)\n",
    "\n",
    "        json_record = {\n",
    "            \"title\": movie_data.get(\"Title\", \"\"),\n",
    "            \"plot\": plot,\n",
    "            \"director\": movie_data.get(\"Director\", \"\"),\n",
    "            \"genre\": genre,\n",
    "            \"rating\": movie_data.get(\"imdbRating\", \"\"),\n",
    "            \"release_date\": movie_data.get(\"Released\", \"\"),\n",
    "            \"language\": \"|\".join(lang.strip() for lang in movie_data.get(\"Language\", \"\").split(\",\")),\n",
    "            \"country\": \"|\".join(c.strip() for c in movie_data.get(\"Country\", \"\").split(\",\")),\n",
    "            \"cast\": \"|\".join(actor.strip() for actor in movie_data.get(\"Actors\", \"\").split(\",\")),\n",
    "            \"poster_url\": poster_url,\n",
    "            \"poster_embedding\": image_embedding,\n",
    "            \"plot_embedding\": text_embedding,\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(json_record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Data written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
